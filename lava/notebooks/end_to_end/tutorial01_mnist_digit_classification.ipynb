{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (C) 2021 Intel Corporation*<br>\n",
    "*SPDX-License-Identifier: BSD-3-Clause*<br>\n",
    "*See: https://spdx.org/licenses/*\n",
    "\n",
    "---\n",
    "\n",
    "# MNIST Digit Classification with Lava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Motivation**: In this tutorial, we will build a Lava Process for an MNIST\n",
    "classifier, using the Lava Processes for LIF neurons and Dense connectivity.\n",
    "Between those leaning towards Neuroscience and those partial to Computer\n",
    "Science, this tutorial aims to be appealing to the former. It is supposed to\n",
    "get one started with Lava in a few minutes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This tutorial assumes that you:\n",
    "- have the [Lava framework installed](../in_depth/tutorial01_installing_lava.ipynb \"Tutorial on Installing Lava\")\n",
    "- are familiar with the [Process concept in Lava](../in_depth/tutorial02_processes.ipynb \"Tutorial on Processes\")\n",
    "\n",
    "### This tutorial gives a bird's-eye-view of\n",
    "- how Lava Process(es) can perform the MNIST digit classification task using\n",
    "[Leaky Integrate-and-Fire (LIF)](https://github.com/lava-nc/lava/tree/main/lava/proc/lif \"Lava's LIF neuron\") neurons and [Dense\n",
    "(fully connected)](https://github.com/lava-nc/lava/tree/main/lava/proc/dense \"Lava's Dense Connectivity\") connectivity.\n",
    "- how to create a Process \n",
    "- how to create Python ProcessModels \n",
    "- how to connect Processes\n",
    "- how to execute them\n",
    "\n",
    "### Follow the links below for deep-dive tutorials on\n",
    "- [Processes](../in_depth/tutorial02_processes.ipynb \"Tutorial on Processes\")\n",
    "- [ProcessModel](../in_depth/tutorial03_process_models.ipynb \"Tutorial on ProcessModels\")\n",
    "- [Execution](../in_depth/tutorial04_execution.ipynb \"Tutorial on Executing Processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our MNIST Classifier\n",
    "In this tutorial, we will build a multi-layer feed-forward classifier without\n",
    " any convolutional layers. The architecture is shown below.\n",
    "\n",
    "> **Important Note**:\n",
    ">\n",
    "> Right now, this model uses arbitrary _untrained_ network paramters (weights and biases)! We will update this model and fix this shortcoming in the next few days after release.\n",
    "> Thus the MNIST classifier is not expected to produce any meaningful output at this point in time. \n",
    "> Nevertheless, this example illustrates how to build, compile and run an otherwise functional model in Lava."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/lava-nc/lava-nc.github.io/main/_static/images/tutorial01/mnist_process_arch.png\" alt=\"Training\n",
    "flow\"\n",
    "style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 Processes shown above are:\n",
    " 1. Spike Input Process - generates spikes via integrate and fire dynamics,\n",
    " using the image input\n",
    " 2. MNIST Feed-forward process - encapsulates feed-forward architecture of\n",
    " Dense connectivity and LIF neurons\n",
    " 3. Output Process - accumulates output spikes from the feed-forward process\n",
    "and infers the class label; compares the predicted class label with the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes: $PYTHONPATH contains lava repository root\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Process class\n",
    "\n",
    "Below we create the Lava Process classes. We need to define only the structure of the process here. The details about how the Process will be executed are specified in the [ProcessModels](../in_depth/tutorial03_process_models.ipynb \"Tutorial on ProcessModels\") below.\n",
    "\n",
    "As mentioned above, we define Processes for \n",
    "- converting input images to binary spikes from those biases (_SpikeInput_),\n",
    "- the 4-layer fully connected feed-forward network (_MnistClassifier_)\n",
    "- accumulating the output spikes and inferring the class for an input image\n",
    "(_OutputProcess_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Process level premitives\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeInput(AbstractProcess):\n",
    "    \"\"\"Reads image data from the MNIST dataset and converts it to spikes.\n",
    "    The resulting spike rate is proportional to the pixel value\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        n_img = kwargs.pop('num_images', 25)\n",
    "        n_steps_img = kwargs.pop('num_steps_per_image', 128)\n",
    "        shape = (784,)\n",
    "        self.spikes_out = OutPort(shape=shape)\n",
    "        self.label_out = OutPort(shape=(1,))\n",
    "        self.num_images = Var(shape=(1,), init=n_img)\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=n_steps_img)\n",
    "        self.input_img = Var(shape=shape)\n",
    "        self.ground_truth_label = Var(shape=(1,))\n",
    "        self.v = Var(shape=shape, init=0)\n",
    "        self.vth = Var(shape=(1,), init=kwargs['vth'])\n",
    "        \n",
    "        \n",
    "class MnistClassifier(AbstractProcess):\n",
    "    \"\"\"A 4 layer feed-forward network with LIF and Dense Processes.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # As mentioned before, the weights and biases saved on the disk are\n",
    "        # arbitrary numbers. These will not produce any meaningful output\n",
    "        # classification.\n",
    "        trained_weights_path = kwargs.pop('trained_weights_path', os.path\n",
    "                                          .join('.','mnist_pretrained.npy'))\n",
    "        real_path_trained_wgts = os.path.realpath(trained_weights_path)\n",
    "\n",
    "        wb_list = np.load(real_path_trained_wgts, allow_pickle=True)\n",
    "        w0 = wb_list[0].transpose().astype(np.int32)\n",
    "        w1 = wb_list[2].transpose().astype(np.int32)\n",
    "        w2 = wb_list[4].transpose().astype(np.int32)\n",
    "        b1 = wb_list[1].astype(np.int32)\n",
    "        b2 = wb_list[3].astype(np.int32)\n",
    "        b3 = wb_list[5].astype(np.int32)\n",
    "\n",
    "        self.spikes_in = InPort(shape=(w0.shape[1],))\n",
    "        self.spikes_out = OutPort(shape=(w2.shape[0],))\n",
    "        self.w_dense0 = Var(shape=w0.shape, init=w0)\n",
    "        self.b_lif1 = Var(shape=(w0.shape[0],), init=b1)\n",
    "        self.w_dense1 = Var(shape=w1.shape, init=w1)\n",
    "        self.b_lif2 = Var(shape=(w1.shape[0],), init=b2)\n",
    "        self.w_dense2 = Var(shape=w2.shape, init=w2)\n",
    "        self.b_output_lif = Var(shape=(w2.shape[0],), init=b3)\n",
    "        \n",
    "        \n",
    "class OutputProcess(AbstractProcess):\n",
    "    \"\"\"Process to gather spikes from 10 output LIF neurons and interpret the\n",
    "    highest spiking rate as the classifier output\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        shape = (10,)\n",
    "        n_img = kwargs.pop('num_images', 25)\n",
    "        self.num_images = Var(shape=(1,), init=n_img)\n",
    "        self.spikes_in = InPort(shape=shape)\n",
    "        self.label_in = InPort(shape=(1,))\n",
    "        self.spikes_accum = Var(shape=shape)\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=128)\n",
    "        self.pred_labels = Var(shape=(n_img,))\n",
    "        self.gt_labels = Var(shape=(n_img,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create ProcessModels for Python execution\n",
    "The code in these ProcessModels is what will get executed. Processes above\n",
    "were declarations, in a way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import parent classes for ProcessModels\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "\n",
    "# Import MNIST dataset\n",
    "from lava.utils.dataloader.mnist import MnistDataset\n",
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ProcessModel for producing spiking input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32,\n",
    "                                      precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    input_img: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    vth: int = LavaPyType(int, int, precision=32)\n",
    "    mnist_dataset = MnistDataset()\n",
    "    curr_img_id = -1\n",
    "\n",
    "    def post_guard(self):\n",
    "        if self.current_ts % self.num_steps_per_image == 1:\n",
    "            self.curr_img_id += 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        img = self.mnist_dataset.images[self.curr_img_id]\n",
    "        self.ground_truth_label = self.mnist_dataset.labels[self.curr_img_id]\n",
    "        self.input_img = img.astype(np.int32) - 127\n",
    "        self.v = np.zeros(self.v.shape)\n",
    "        self.label_out.send(np.array([self.ground_truth_label]))\n",
    "\n",
    "    def run_spk(self):\n",
    "        self.v[:] = self.v + self.input_img\n",
    "        s_out = self.v > self.vth\n",
    "        self.v[s_out] = 0  # reset voltage to 0 after a spike\n",
    "        self.spikes_out.send(s_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ProcessModel for the feed-forward network\n",
    "Notice that the following process model is further decomposed into\n",
    "sub-Processes, which implement LIF neural dynamics and Dense connectivity. We\n",
    " will not go into the details of how these are implemented in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense            \n",
    "\n",
    "@implements(MnistClassifier)\n",
    "@requires(CPU)\n",
    "class PyMnistClassifierModel(AbstractSubProcessModel):\n",
    "    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    w_dense0: np.ndarray = LavaPyType(np.ndarray, int, precision=8)\n",
    "    b_lif1: np.ndarray = LavaPyType(np.ndarray, int, precision=13)\n",
    "    w_dense1: np.ndarray = LavaPyType(np.ndarray, int, precision=8)\n",
    "    b_lif2: np.ndarray = LavaPyType(np.ndarray, int, precision=13)\n",
    "    w_dense2: np.ndarray = LavaPyType(np.ndarray, int, precision=8)\n",
    "    b_output_lif: np.ndarray = LavaPyType(np.ndarray, int, precision=13)\n",
    "\n",
    "    def __init__(self, proc):\n",
    "        self.dense0 = Dense(shape=(64, 784), weights=proc.w_dense0.init)\n",
    "        self.lif1 = LIF(shape=(64,), b=proc.b_lif1.init, vth=400,\n",
    "                        dv=0, du=4095)\n",
    "        self.dense1 = Dense(shape=(64, 64), weights=proc.w_dense1.init)\n",
    "        self.lif2 = LIF(shape=(64,), b=proc.b_lif2.init, vth=350,\n",
    "                        dv=0, du=4095)\n",
    "        self.dense2 = Dense(shape=(10, 64), weights=proc.w_dense2.init)\n",
    "        self.output_lif = LIF(shape=(10,), b=proc.b_output_lif.init,\n",
    "                              vth=2**17-1, dv=0, du=4095)\n",
    "\n",
    "        proc.in_ports.spikes_in.connect(self.dense0.in_ports.s_in)\n",
    "        self.dense0.out_ports.a_out.connect(self.lif1.in_ports.a_in)\n",
    "        self.lif1.out_ports.s_out.connect(self.dense1.in_ports.s_in)\n",
    "        self.dense1.out_ports.a_out.connect(self.lif2.in_ports.a_in)\n",
    "        self.lif2.out_ports.s_out.connect(self.dense2.in_ports.s_in)\n",
    "        self.dense2.out_ports.a_out.connect(self.output_lif.in_ports.a_in)\n",
    "        self.output_lif.out_ports.s_out.connect(proc.out_ports.spikes_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finally, ProcessModel for inference output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@implements(proc=OutputProcess, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyOutputProcessModel(PyLoihiProcessModel):\n",
    "    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "    label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    gt_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    current_img_id = -1\n",
    "\n",
    "    # This is needed for Loihi synchronization protocol\n",
    "    def post_guard(self):\n",
    "        if self.current_ts % self.num_steps_per_image == 1 and self\\\n",
    "                .current_ts > 1:\n",
    "            self.current_img_id += 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        print(f'Curr Img: {self.current_img_id}')\n",
    "        pred_label = np.argmax(self.spikes_accum)\n",
    "        self.pred_labels[self.current_img_id] = pred_label\n",
    "        self.spikes_accum = np.zeros(self.spikes_accum.shape)\n",
    "        gt_label = self.label_in.recv()\n",
    "        self.gt_labels[self.current_img_id] = gt_label\n",
    "        print(f'Pred Label: {pred_label}', end='\\t')\n",
    "        print(f'Ground Truth: {gt_label}')\n",
    "\n",
    "    def run_spk(self):\n",
    "        spikes_buffer = self.spikes_in.recv()\n",
    "        self.spikes_accum += spikes_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr Img: 0\n",
      "Pred Label: 0\tGround Truth: [5]\n",
      "Curr Img: 1\n",
      "Pred Label: 0\tGround Truth: [0]\n",
      "Curr Img: 2\n",
      "Pred Label: 0\tGround Truth: [4]\n",
      "Curr Img: 3\n",
      "Pred Label: 0\tGround Truth: [1]\n",
      "Curr Img: 4\n",
      "Pred Label: 0\tGround Truth: [9]\n"
     ]
    }
   ],
   "source": [
    "num_images = 5\n",
    "num_steps_per_image = 128\n",
    "\n",
    "# Create instances\n",
    "spike_input = SpikeInput(num_images=num_images,\n",
    "                         num_steps_per_image=num_steps_per_image,\n",
    "                         vth=1)\n",
    "mnist_clf = MnistClassifier(\n",
    "    trained_weights_path=os.path.join('.', 'mnist_pretrained.npy'))\n",
    "output_proc = OutputProcess(num_images=num_images)\n",
    "\n",
    "# Connect instances\n",
    "spike_input.out_ports.spikes_out.connect(mnist_clf.in_ports.spikes_in)\n",
    "mnist_clf.out_ports.spikes_out.connect(output_proc.in_ports.spikes_in)\n",
    "spike_input.out_ports.label_out.connect(output_proc.in_ports.label_in)\n",
    "\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "\n",
    "mnist_clf.run(\n",
    "    condition=RunSteps(num_steps=(num_images+1) * num_steps_per_image),\n",
    "    run_cfg=Loihi1SimCfg(select_sub_proc_model=True))\n",
    "mnist_clf.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important Note**:\n",
    ">\n",
    "> Right now, this model uses arbitrary _untrained_ network paramters (weights and biases)! We will update this model and fix this shortcoming in the next few days after release.\n",
    "> Thus the MNIST classifier is not expected to produce any meaningful output at this point in time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to learn more?\n",
    "\n",
    "If you want to find out more about Lava, have a look at the [Lava documentation](https://lava-nc.org/ \"Lava Documentation\") or dive into the [source code](https://github.com/lava-nc/lava/ \"Lava Source Code\").\n",
    "\n",
    "To receive regular updates on the latest developments and releases of the Lava Software Framework please subscribe to the [INRC newsletter](http://eepurl.com/hJCyhb \"INRC Newsletter\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
